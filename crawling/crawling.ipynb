{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b37c570",
   "metadata": {},
   "source": [
    "# pubmed ì—ì„œ ë…¼ë¬¸ì˜ ì œëª©ê³¼ ì´ˆë¡ì„ í¬ë¡¤ë§í•˜ëŠ” ì½”ë“œ ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3a385e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'rehabilitation_articles_openai' ì»¬ë ‰ì…˜ì— ì ‘ê·¼í–ˆìŠµë‹ˆë‹¤. (OpenAI `text-embedding-3-large` ì‚¬ìš©)\n",
      "EDirectë¥¼ ì‚¬ìš©í•˜ì—¬ PubMedì—ì„œ ë‹¤ìŒ ì¿¼ë¦¬ë¡œ ë…¼ë¬¸ IDë¥¼ ê²€ìƒ‰ ì¤‘: '(kinesiology OR \"human movement\" OR biomechanics OR \"motor control\" OR \"physical activity\") OR (pilates) OR (stretching OR flexibility OR \"range of motion\") OR (\"exercise therapy\" OR \"physical therapy\" OR physiotherapy OR \"rehabilitation exercise\" OR \"therapeutic exercise\") AND (2015/01/01[PDAT] : 2025/07/21[PDAT])'\n",
      "ğŸš¨ EDirectê°€ ì‹œìŠ¤í…œ ê²½ë¡œì— ì—†ê±°ë‚˜ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. WSL í™˜ê²½ì— EDirectë¥¼ ë¨¼ì € ì„¤ì¹˜í•´ì£¼ì„¸ìš”.\n",
      "â— ë…¼ë¬¸ IDë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
      "â— ì €ì¥í•  ë…¼ë¬¸ IDê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "ğŸ‰ ì™„ë£Œ: ëª¨ë“  ì´ˆë¡ ë°ì´í„° ìˆ˜ì§‘ ë° ChromaDBì— ì €ì¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mí˜„ì¬ ì…€ ë˜ëŠ” ì´ì „ ì…€ì—ì„œ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ëŠ” ë™ì•ˆ Kernelì´ ì¶©ëŒí–ˆìŠµë‹ˆë‹¤. \n",
      "\u001b[1;31mì…€ì˜ ì½”ë“œë¥¼ ê²€í† í•˜ì—¬ ê°€ëŠ¥í•œ ì˜¤ë¥˜ ì›ì¸ì„ ì‹ë³„í•˜ì„¸ìš”. \n",
      "\u001b[1;31mìì„¸í•œ ë‚´ìš©ì„ ë³´ë ¤ë©´ <a href='https://aka.ms/vscodeJupyterKernelCrash'>ì—¬ê¸°</a>ë¥¼ í´ë¦­í•˜ì„¸ìš”. \n",
      "\u001b[1;31mìì„¸í•œ ë‚´ìš©ì€ Jupyter <a href='command:jupyter.viewOutput'>ë¡œê·¸</a>ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n",
    "from Bio import Entrez\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "# ---\n",
    "## 1. í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì •\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "DATABASE_PATH = \"./chroma_pubmed_abstract_only\"\n",
    "COLLECTION_NAME = \"rehabilitation_articles_openai\"\n",
    "\n",
    "# ---\n",
    "## 2. ChromaDB ë° ì„ë² ë”© ì„¤ì •\n",
    "chroma_client = chromadb.PersistentClient(\n",
    "    path=DATABASE_PATH,\n",
    "    settings=Settings(allow_reset=True)\n",
    ")\n",
    "\n",
    "embedding_function = OpenAIEmbeddingFunction(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model_name=\"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=COLLECTION_NAME,\n",
    "    embedding_function=embedding_function\n",
    ")\n",
    "\n",
    "# ---\n",
    "## 3. PubMed ê²€ìƒ‰ ì„¤ì •\n",
    "# Entrez API ì‚¬ìš© ì‹œ ì´ë©”ì¼ì€ í•„ìˆ˜ì…ë‹ˆë‹¤.\n",
    "Entrez.email = \"your_email@example.com\"  \n",
    "\n",
    "SEARCH_QUERY = (\n",
    "    '(kinesiology OR \"human movement\" OR biomechanics OR \"motor control\" OR \"physical activity\") OR '\n",
    "    '(pilates) OR (stretching OR flexibility OR \"range of motion\") OR '\n",
    "    '(\"exercise therapy\" OR \"physical therapy\" OR physiotherapy OR \"rehabilitation exercise\" OR \"therapeutic exercise\")'\n",
    ")\n",
    "\n",
    "# í˜„ì¬ ë‚ ì§œ ê¸°ì¤€ ìµœê·¼ 10ë…„ì¹˜ ë°ì´í„°\n",
    "TODAY = time.strftime(\"%Y/%m/%d\")\n",
    "TEN_YEARS_AGO = f\"{int(time.strftime('%Y')) - 10}/01/01\"\n",
    "DATE_RANGE = f\"({TEN_YEARS_AGO}[PDAT] : {TODAY}[PDAT])\"\n",
    "\n",
    "# Entrez.esearchê°€ í•œ ë²ˆì— ë°˜í™˜í•  ìˆ˜ ìˆëŠ” ìµœëŒ€ ID ìˆ˜ (PubMedì˜ ì œí•œ)\n",
    "MAX_IDS_PER_PAGINATION_REQUEST = 9999 \n",
    "# Bio.Entrez.efetch ì‹œ í•œ ë²ˆì— ì²˜ë¦¬í•  ë…¼ë¬¸ ìˆ˜ (ChromaDB ì €ì¥ ë°°ì¹˜ì™€ë„ ì—°ê´€)\n",
    "BATCH_SIZE = 500 \n",
    "\n",
    "# ---\n",
    "## 4. PubMed ê²€ìƒ‰ ID ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜ (í˜ì´ì§€ë„¤ì´ì…˜ êµ¬í˜„)\n",
    "def search_article_ids_paginated(query: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Bio.Entrez.esearchë¥¼ ì‚¬ìš©í•˜ì—¬ PubMedì—ì„œ ë…¼ë¬¸ ID ëª©ë¡ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
    "    10,000ê°œ ì œí•œì„ ìš°íšŒí•˜ê¸° ìœ„í•´ í˜ì´ì§€ë„¤ì´ì…˜ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    full_query = f\"{query} AND {DATE_RANGE}\"\n",
    "    print(f\"PubMedì—ì„œ ë‹¤ìŒ ì¿¼ë¦¬ë¡œ ì „ì²´ ë…¼ë¬¸ ìˆ˜ë¥¼ í™•ì¸ ì¤‘: '{full_query}'\")\n",
    "    \n",
    "    all_id_list = []\n",
    "    \n",
    "    try:\n",
    "        # 1. ì „ì²´ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ í™•ì¸\n",
    "        handle = Entrez.esearch(db=\"pubmed\", term=full_query, retmax=0) # retmax=0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ê°œìˆ˜ë§Œ ê°€ì ¸ì˜´\n",
    "        results = Entrez.read(handle)\n",
    "        handle.close()\n",
    "        \n",
    "        total_articles = int(results[\"Count\"])\n",
    "        print(f\"ğŸ” í•´ë‹¹ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰ëœ ì´ ë…¼ë¬¸ ìˆ˜ëŠ” {total_articles}ê°œ ì…ë‹ˆë‹¤.\")\n",
    "        \n",
    "        # 2. í˜ì´ì§€ë„¤ì´ì…˜ì„ í†µí•´ ID ê°€ì ¸ì˜¤ê¸°\n",
    "        for start_index in range(0, total_articles, MAX_IDS_PER_PAGINATION_REQUEST):\n",
    "            print(f\"ğŸ“„ {start_index}ë¶€í„° {min(start_index + MAX_IDS_PER_PAGINATION_REQUEST, total_articles)}ê¹Œì§€ì˜ ë…¼ë¬¸ ID ê²€ìƒ‰ ì¤‘...\")\n",
    "            handle = Entrez.esearch(\n",
    "                db=\"pubmed\",\n",
    "                term=full_query,\n",
    "                retmax=MAX_IDS_PER_PAGINATION_REQUEST, # í•œ ë²ˆì— ê°€ì ¸ì˜¬ ìµœëŒ€ ID ìˆ˜\n",
    "                retstart=start_index       # ê²€ìƒ‰ ì‹œì‘ ìœ„ì¹˜ (ì˜¤í”„ì…‹)\n",
    "            )\n",
    "            results = Entrez.read(handle)\n",
    "            handle.close()\n",
    "            all_id_list.extend(results[\"IdList\"])\n",
    "            \n",
    "            # NCBI ìš”ì²­ ì œí•œì„ ì¤€ìˆ˜í•˜ê¸° ìœ„í•´ ì ì‹œ ëŒ€ê¸°\n",
    "            time.sleep(0.5) \n",
    "            \n",
    "            # ì˜ˆìƒì¹˜ ëª»í•œ ìƒí™©ìœ¼ë¡œ IDë¥¼ ë” ì´ìƒ ê°€ì ¸ì˜¤ì§€ ëª»í•˜ë©´ ì¤‘ë‹¨ (ì˜ˆ: ê²€ìƒ‰ ê²°ê³¼ê°€ ê°‘ìê¸° ì¤„ê±°ë‚˜)\n",
    "            if not results[\"IdList\"] or len(results[\"IdList\"]) < MAX_IDS_PER_PAGINATION_REQUEST:\n",
    "                # ë§ˆì§€ë§‰ í˜ì´ì§€ì´ê±°ë‚˜ ë” ì´ìƒ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°\n",
    "                if start_index + len(results[\"IdList\"]) >= total_articles:\n",
    "                    break\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"ğŸš¨ ë…¼ë¬¸ ID ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return []\n",
    "\n",
    "    print(f\"ğŸ” ìµœì¢…ì ìœ¼ë¡œ ì´ {len(all_id_list)}ê°œì˜ ë…¼ë¬¸ ID ê²€ìƒ‰ë¨.\")\n",
    "    return all_id_list\n",
    "\n",
    "# ---\n",
    "## 5. ì´ˆë¡ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ë° ChromaDBì— ë°”ë¡œ ì €ì¥ í•¨ìˆ˜ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )\n",
    "def fetch_and_save_abstracts(id_list: List[str]):\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ ID ëª©ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ PubMedì—ì„œ ë…¼ë¬¸ì˜ ì´ˆë¡ ì •ë³´ë¥¼ ê°€ì ¸ì™€ ChromaDBì— ë°”ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "    ëª¨ë“  ì´ˆë¡ì„ ë©”ëª¨ë¦¬ì— í•œêº¼ë²ˆì— ë¡œë“œí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì…ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    if not id_list:\n",
    "        print(\"â— ì €ì¥í•  ë…¼ë¬¸ IDê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    print(f\"ì´ {len(id_list)}ê°œì˜ IDì—ì„œ ì´ˆë¡ì„ ê°€ì ¸ì™€ ChromaDBì— ì €ì¥ ì¤‘...\")\n",
    "    \n",
    "    temp_documents = []\n",
    "    temp_metadatas = []\n",
    "    temp_ids = []\n",
    "    \n",
    "    saved_count = 0 # ì‹¤ì œë¡œ ì €ì¥ëœ ì´ˆë¡ì˜ ê°œìˆ˜\n",
    "\n",
    "    for start in range(0, len(id_list), BATCH_SIZE):\n",
    "        end = start + BATCH_SIZE\n",
    "        batch_ids = id_list[start:end]\n",
    "        print(f\"ğŸ“š ë°°ì¹˜ {start} ~ {min(end, len(id_list))} ì²˜ë¦¬ ì¤‘...\")\n",
    "        try:\n",
    "            handle = Entrez.efetch(db=\"pubmed\", id=','.join(batch_ids), rettype=\"abstract\", retmode=\"xml\")\n",
    "            records = Entrez.read(handle)\n",
    "            handle.close()\n",
    "            \n",
    "            for article in records.get(\"PubmedArticle\", []):\n",
    "                pmid = article[\"MedlineCitation\"][\"PMID\"]\n",
    "                article_info = article[\"MedlineCitation\"].get(\"Article\", {})\n",
    "                title = article_info.get(\"ArticleTitle\", \"\")\n",
    "                \n",
    "                abstract_parts = article_info.get(\"Abstract\", {}).get(\"AbstractText\", [])\n",
    "                abstract = \" \".join(abstract_parts)\n",
    "                \n",
    "                if abstract: \n",
    "                    temp_documents.append(abstract)\n",
    "                    temp_metadatas.append({\"title\": title})\n",
    "                    temp_ids.append(str(pmid))\n",
    "            \n",
    "            # ì¼ì •ëŸ‰ì˜ ë°ì´í„°ê°€ ëª¨ì´ë©´ ChromaDBì— ì €ì¥\n",
    "            if len(temp_documents) >= BATCH_SIZE: \n",
    "                print(f\"âœ… ChromaDBì— ì¤‘ê°„ ì €ì¥: {len(temp_documents)}ê°œ í•­ëª© ì¶”ê°€ ì¤‘...\")\n",
    "                collection.add(\n",
    "                    documents=temp_documents,\n",
    "                    metadatas=temp_metadatas,\n",
    "                    ids=temp_ids\n",
    "                )\n",
    "                saved_count += len(temp_documents)\n",
    "                temp_documents.clear()\n",
    "                temp_metadatas.clear()\n",
    "                temp_ids.clear()\n",
    "            \n",
    "            time.sleep(0.5) # NCBI ìš”ì²­ ì œí•œ ì¤€ìˆ˜\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ë°°ì¹˜ {start}-{end} ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜ ë°œìƒ:\", e)\n",
    "            time.sleep(1) \n",
    "            continue \n",
    "            \n",
    "    # ë£¨í”„ ì¢…ë£Œ í›„ ë‚¨ì•„ìˆëŠ” í•­ëª©ë“¤ ìµœì¢… ì €ì¥\n",
    "    if temp_documents:\n",
    "        print(f\"âœ… ChromaDBì— ìµœì¢… ì €ì¥: ë‚¨ì€ {len(temp_documents)}ê°œ í•­ëª© ì¶”ê°€ ì¤‘...\")\n",
    "        collection.add(\n",
    "            documents=temp_documents,\n",
    "            metadatas=temp_metadatas,\n",
    "            ids=temp_ids\n",
    "        )\n",
    "        saved_count += len(temp_documents)\n",
    "    \n",
    "    print(f\"ğŸ“„ ì´ {saved_count}ê°œì˜ ìœ íš¨í•œ ì´ˆë¡ì´ ChromaDBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ---\n",
    "## 6. ë©”ì¸ ì‹¤í–‰ ë¸”ë¡\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"'{COLLECTION_NAME}' ì»¬ë ‰ì…˜ì— ì ‘ê·¼í–ˆìŠµë‹ˆë‹¤. (OpenAI `text-embedding-3-large` ì‚¬ìš©)\")\n",
    "    try:\n",
    "        # í˜ì´ì§€ë„¤ì´ì…˜ ë¡œì§ì„ ì‚¬ìš©í•˜ëŠ” ID ê²€ìƒ‰ í•¨ìˆ˜ í˜¸ì¶œ\n",
    "        id_list = search_article_ids_paginated(SEARCH_QUERY)\n",
    "        \n",
    "        # ê²€ìƒ‰ëœ IDê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ\n",
    "        if not id_list:\n",
    "            print(\"â— ë…¼ë¬¸ IDë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‘ì—…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            exit()\n",
    "        \n",
    "        # ê²€ìƒ‰ëœ IDë¡œ ì´ˆë¡ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ë° ChromaDBì— ë°”ë¡œ ì €ì¥\n",
    "        fetch_and_save_abstracts(id_list)\n",
    "        \n",
    "        print(\"ğŸ‰ ì™„ë£Œ: ëª¨ë“  ì´ˆë¡ ë°ì´í„° ìˆ˜ì§‘ ë° ChromaDBì— ì €ì¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸš¨ ì „ì²´ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb480f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
